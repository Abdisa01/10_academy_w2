{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#task 1.2 exploratory data analysis on those data & communicate useful insights. \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "# Load the datasets from CSV files\n",
    "telecom_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/GitHub/Data-weak2/Data/Copy of Week2_challenge_data_source(CSV).csv')\n",
    "print(\"Telecom Data:\")\n",
    "print(telecom_df.head())\n",
    "\n",
    "# Step 1: Identify the Top 10 Handsets Used by Customers (based on Handset Type)\n",
    "top_handsets = telecom_df['Handset Type'].value_counts().head(10)\n",
    "print(\"\\nTop 10 Handsets:\\n\", top_handsets)\n",
    "# Check for data types and missing values\n",
    "print(telecom_df.info())\n",
    "print(telecom_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Identify non-numeric columns\n",
    "non_numeric_columns = telecom_df.select_dtypes(include=['object']).columns\n",
    "print(\"\\nNon-Numeric Columns:\")\n",
    "print(non_numeric_columns)\n",
    "# Convert 'Start' and 'End' to datetime\n",
    "telecom_df['Start'] = pd.to_datetime(telecom_df['Start'], errors='coerce')\n",
    "telecom_df['End'] = pd.to_datetime(telecom_df['End'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Convert all other columns to numeric, coercing errors\n",
    "for col in telecom_df.columns:\n",
    "    if col not in ['Start', 'End'] + list(non_numeric_columns):\n",
    "        telecom_df[col] = pd.to_numeric(telecom_df[col], errors='coerce')\n",
    "# Display missing values for analysis\n",
    "missing_values = telecom_df.isnull().sum()\n",
    "print(\"\\nMissing values before filling:\")\n",
    "print(missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Fill or handle missing values based on the context\n",
    "# List of numeric columns to fill with mean/median\n",
    "numeric_columns = [\n",
    "    'Start', 'Start ms', 'End', 'End ms', 'Dur. (ms)', 'Avg RTT DL (ms)', \n",
    "    'Avg RTT UL (ms)', 'Avg Bearer TP DL (kbps)', 'Avg Bearer TP UL (kbps)', \n",
    "    'TCP DL Retrans. Vol (Bytes)', 'TCP UL Retrans. Vol (Bytes)', \n",
    "    'DL TP < 50 Kbps (%)', '50 Kbps < DL TP < 250 Kbps (%)', \n",
    "    '250 Kbps < DL TP < 1 Mbps (%)', 'DL TP > 1 Mbps (%)', \n",
    "    'UL TP < 10 Kbps (%)', '10 Kbps < UL TP < 50 Kbps (%)', \n",
    "    '50 Kbps < UL TP < 300 Kbps (%)', 'UL TP > 300 Kbps (%)', \n",
    "    'HTTP DL (Bytes)', 'HTTP UL (Bytes)', 'Activity Duration DL (ms)', \n",
    "    'Activity Duration UL (ms)', 'Dur. (ms).1', \n",
    "    'Nb of sec with 125000B < Vol DL', 'Nb of sec with 1250B < Vol UL < 6250B', \n",
    "    'Nb of sec with 31250B < Vol DL < 125000B', 'Nb of sec with 37500B < Vol UL', \n",
    "    'Nb of sec with 6250B < Vol DL < 31250B', 'Nb of sec with 6250B < Vol UL < 37500B', \n",
    "    'Nb of sec with Vol DL < 6250B', 'Nb of sec with Vol UL < 1250B', \n",
    "    'Total UL (Bytes)', 'Total DL (Bytes)'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Fill numeric columns with mean\n",
    "for col in numeric_columns:\n",
    "    if telecom_df[col].isnull().sum() > 0:\n",
    "        telecom_df[col].fillna(telecom_df[col].mean(), inplace=True)\n",
    " # Handle categorical columns\n",
    "categorical_columns = ['Last Location Name', 'Handset Manufacturer', 'Handset Type']\n",
    "for col in categorical_columns:\n",
    "    if telecom_df[col].isnull().sum() > 0:\n",
    "        telecom_df[col].fillna(telecom_df[col].mode()[0], inplace=True)       \n",
    "# Verify that there are no more missing values\n",
    "print(\"\\nMissing values after filling:\")\n",
    "print(telecom_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Calculate Total Duration for each user\n",
    "# Using 'IMSI' as the user identifier\n",
    "user_total_duration = telecom_df.groupby('IMSI')['Dur. (ms)'].sum().reset_index()\n",
    "user_total_duration.rename(columns={'Dur. (ms)': 'Total_Duration'}, inplace=True)\n",
    "# Step 2: Create Decile Classes\n",
    "user_total_duration['Decile_Class'] = pd.qcut(user_total_duration['Total_Duration'], 10, labels=False) + 1\n",
    "# Step 3: Compute Total Data for each user\n",
    "data_per_user = telecom_df.groupby('IMSI')[['Total DL (Bytes)', 'Total UL (Bytes)']].sum().reset_index()\n",
    "data_per_user['Total_Data'] = data_per_user['Total DL (Bytes)'] + data_per_user['Total UL (Bytes)']\n",
    "# Merge the total duration with the data per user\n",
    "merged_data = pd.merge(user_total_duration, data_per_user, on='IMSI')\n",
    "# Step 4: Compute Total Data per Decile Class\n",
    "decile_summary = merged_data.groupby('Decile_Class')['Total_Data'].sum().reset_index()\n",
    "# Display the summary\n",
    "print(\"\\nTotal Data per Decile Class:\")\n",
    "print(decile_summary)\n",
    "decile_summary['Total_Data'] = decile_summary['Total_Data'] / 1e6  # Convert to Megabytes for better readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Create a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Decile_Class', y='Total_Data', data=decile_summary, palette='viridis')\n",
    "plt.title('Total Data (DL + UL) per Decile Class')\n",
    "plt.xlabel('Decile Class')\n",
    "plt.ylabel('Total Data (MB)')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# Step 3: Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Function to identify outliers using IQR\n",
    "def identify_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# List of numeric columns to check for outliers\n",
    "numeric_columns = [\n",
    "    'Dur. (ms)', 'Total DL (Bytes)', 'Total UL (Bytes)',\n",
    "    'Avg RTT DL (ms)', 'Avg RTT UL (ms)', 'Avg Bearer TP DL (kbps)',\n",
    "    'Avg Bearer TP UL (kbps)', 'TCP DL Retrans. Vol (Bytes)',\n",
    "    'TCP UL Retrans. Vol (Bytes)', 'HTTP DL (Bytes)', 'HTTP UL (Bytes)',\n",
    "    'Activity Duration DL (ms)', 'Activity Duration UL (ms)',\n",
    "    'Total UL (Bytes)', 'Total DL (Bytes)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Identify outliers for each numeric column\n",
    "for col in numeric_columns:\n",
    "    outliers = identify_outliers_iqr(telecom_df, col)\n",
    "    print(f\"\\nOutliers in {col}:\")\n",
    "    print(outliers)\n",
    "# Function to create boxplots for numeric columns\n",
    "def plot_boxplots(df, columns):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, col in enumerate(columns, 1):\n",
    "        plt.subplot(4, 4, i)  # Adjust the number of rows/columns based on the number of plots\n",
    "        sns.boxplot(x=df[col])\n",
    "        plt.title(f'Boxplot of {col}')\n",
    "        plt.xlabel(col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Plot boxplots for numeric columns\n",
    "plot_boxplots(telecom_df, numeric_columns)\n",
    "\n",
    "# Function to identify rare categories and group them\n",
    "def group_rare_categories(df, column, threshold=0.05):\n",
    "    # Calculate frequency of each category\n",
    "    freq = df[column].value_counts(normalize=True)\n",
    "    \n",
    "    # Identify categories below the threshold\n",
    "    rare_categories = freq[freq < threshold].index\n",
    "    \n",
    "    # Group rare categories into 'Other'\n",
    "    df[column] = df[column].replace(rare_categories, 'Other')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Apply to categorical columns\n",
    "for col in ['Last Location Name', 'Handset Manufacturer', 'Handset Type']:\n",
    "    telecom_df = group_rare_categories(telecom_df, col)\n",
    "\n",
    "# Display the updated categorical data\n",
    "print(telecom_df['Handset Manufacturer'].value_counts())\n",
    "\n",
    "# Function to plot categorical data\n",
    "def plot_categorical_counts(df, column):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(x=df[column], order=df[column].value_counts().index)\n",
    "    plt.title(f'Count of Categories in {column}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Plot for each categorical column\n",
    "for col in ['Last Location Name', 'Handset Manufacturer', 'Handset Type']:\n",
    "    plot_categorical_counts(telecom_df, col)\n",
    "# Calculate basic metrics for relevant columns\n",
    "metrics_summary = {\n",
    "    'Total Duration (ms)': {\n",
    "        'Mean': telecom_df['Dur. (ms)'].mean(),\n",
    "        'Median': telecom_df['Dur. (ms)'].median(),\n",
    "        'Mode': telecom_df['Dur. (ms)'].mode()[0],\n",
    "        'Standard Deviation': telecom_df['Dur. (ms)'].std(),\n",
    "        'Range': telecom_df['Dur. (ms)'].max() - telecom_df['Dur. (ms)'].min(),\n",
    "        '25th Percentile': telecom_df['Dur. (ms)'].quantile(0.25),\n",
    "        '75th Percentile': telecom_df['Dur. (ms)'].quantile(0.75)\n",
    "    },\n",
    "    'Total Data (Bytes)': {\n",
    "        'Mean': telecom_df['Total DL (Bytes)'].sum() + telecom_df['Total UL (Bytes)'].sum(),\n",
    "        'Median': telecom_df['Total DL (Bytes)'].median() + telecom_df['Total UL (Bytes)'].median(),\n",
    "        # More calculations as needed\n",
    "    }\n",
    "}\n",
    "# Display the metrics summary\n",
    "import pprint\n",
    "pprint.pprint(metrics_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# List of quantitative columns to analyze\n",
    "quantitative_columns = [\n",
    "    'Dur. (ms)', 'Avg RTT DL (ms)', 'Avg RTT UL (ms)',\n",
    "    'Avg Bearer TP DL (kbps)', 'Avg Bearer TP UL (kbps)',\n",
    "    'TCP DL Retrans. Vol (Bytes)', 'TCP UL Retrans. Vol (Bytes)',\n",
    "    'HTTP DL (Bytes)', 'HTTP UL (Bytes)', 'Activity Duration DL (ms)',\n",
    "    'Activity Duration UL (ms)', 'Total DL (Bytes)', 'Total UL (Bytes)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dictionary to store metrics for each column\n",
    "metrics_summary = {}\n",
    "\n",
    "# Compute metrics for each quantitative variable\n",
    "for column in quantitative_columns:\n",
    "    metrics_summary[column] = {\n",
    "        'Mean': telecom_df[column].mean(),\n",
    "        'Median': telecom_df[column].median(),\n",
    "        'Standard Deviation': telecom_df[column].std(),\n",
    "        'Range': telecom_df[column].max() - telecom_df[column].min(),\n",
    "        '25th Percentile': telecom_df[column].quantile(0.25),\n",
    "        '75th Percentile': telecom_df[column].quantile(0.75),\n",
    "        'IQR': telecom_df[column].quantile(0.75) - telecom_df[column].quantile(0.25)\n",
    "    }\n",
    "\n",
    "# Display the metrics summary\n",
    "import pprint\n",
    "pprint.pprint(metrics_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Set the style for the plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# List of quantitative columns to analyze\n",
    "quantitative_columns = [\n",
    "    'Dur. (ms)', 'Avg RTT DL (ms)', 'Avg RTT UL (ms)',\n",
    "    'Avg Bearer TP DL (kbps)', 'Avg Bearer TP UL (kbps)',\n",
    "    'TCP DL Retrans. Vol (Bytes)', 'TCP UL Retrans. Vol (Bytes)',\n",
    "    'HTTP DL (Bytes)', 'HTTP UL (Bytes)', 'Activity Duration DL (ms)',\n",
    "    'Activity Duration UL (ms)', 'Total DL (Bytes)', 'Total UL (Bytes)'\n",
    "]\n",
    "# Create a figure for the plots\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Generate plots for each variable\n",
    "for i, column in enumerate(quantitative_columns):\n",
    "    plt.subplot(5, 3, i + 1)  # Arrange in a 5x3 grid\n",
    "    sns.histplot(telecom_df[column], kde=True, bins=30)\n",
    "    plt.title(column)\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Box plots for key variables\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.boxplot(data=telecom_df[quantitative_columns])\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Box Plots of Quantitative Variables')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create a new column for total data\n",
    "telecom_df['Total Data (Bytes)'] = telecom_df['Total DL (Bytes)'] + telecom_df['Total UL (Bytes)']\n",
    "# List of application columns for data usage\n",
    "application_columns = [\n",
    "    'Social Media DL (Bytes)', 'Social Media UL (Bytes)',\n",
    "    'Google DL (Bytes)', 'Google UL (Bytes)',\n",
    "    'Email DL (Bytes)', 'Email UL (Bytes)',\n",
    "    'Youtube DL (Bytes)', 'Youtube UL (Bytes)',\n",
    "    'Netflix DL (Bytes)', 'Netflix UL (Bytes)',\n",
    "    'Gaming DL (Bytes)', 'Gaming UL (Bytes)',\n",
    "    'Other DL (Bytes)', 'Other UL (Bytes)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Correlation Analysis\n",
    "correlation_results = {}\n",
    "for app in application_columns:\n",
    "    # Calculate correlation with total data for each application\n",
    "    correlation_dl = telecom_df[app].corr(telecom_df['Total Data (Bytes)'])\n",
    "    correlation_results[app] = correlation_dl\n",
    "\n",
    "print(\"Correlation Coefficients with Total Data:\")\n",
    "for app, corr in correlation_results.items():\n",
    "    print(f\"{app}: {corr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Scatter Plots\n",
    "plt.figure(figsize=(18, 12))\n",
    "for i, app in enumerate(application_columns):\n",
    "    plt.subplot(4, 4, i + 1)  # Arrange in a 4x4 grid\n",
    "    sns.scatterplot(x=telecom_df[app], y=telecom_df['Total Data (Bytes)'])\n",
    "    plt.title(f'Scatter Plot: {app} vs Total Data')\n",
    "    plt.xlabel(app)\n",
    "    plt.ylabel('Total Data (Bytes)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 3. Group By Analysis\n",
    "grouped_data = telecom_df[application_columns].sum().reset_index()\n",
    "grouped_data.columns = ['Application', 'Total Data (Bytes)']\n",
    "print(\"\\nTotal Data by Application:\")\n",
    "print(grouped_data.sort_values(by='Total Data (Bytes)', ascending=False))\n",
    "# Select relevant columns for correlation analysis\n",
    "correlation_columns = [\n",
    "    'Social Media DL (Bytes)', 'Social Media UL (Bytes)',\n",
    "    'Google DL (Bytes)', 'Google UL (Bytes)',\n",
    "    'Email DL (Bytes)', 'Email UL (Bytes)',\n",
    "    'Youtube DL (Bytes)', 'Youtube UL (Bytes)',\n",
    "    'Netflix DL (Bytes)', 'Netflix UL (Bytes)',\n",
    "    'Gaming DL (Bytes)', 'Gaming UL (Bytes)',\n",
    "    'Other DL (Bytes)', 'Other UL (Bytes)'\n",
    "]\n",
    "# Create a DataFrame with the selected columns\n",
    "data_for_correlation = telecom_df[correlation_columns]\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = data_for_correlation.corr()\n",
    "\n",
    "# Print the correlation matrix\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', square=True, cbar_kws={\"shrink\": .8})\n",
    "plt.title('Correlation Matrix for Application Data Usage')\n",
    "plt.show()\n",
    "\n",
    "# Select relevant columns for PCA (using only application data columns)\n",
    "pca_columns = [\n",
    "    'Social Media DL (Bytes)', 'Social Media UL (Bytes)',\n",
    "    'Google DL (Bytes)', 'Google UL (Bytes)',\n",
    "    'Email DL (Bytes)', 'Email UL (Bytes)',\n",
    "    'Youtube DL (Bytes)', 'Youtube UL (Bytes)',\n",
    "    'Netflix DL (Bytes)', 'Netflix UL (Bytes)',\n",
    "    'Gaming DL (Bytes)', 'Gaming UL (Bytes)',\n",
    "    'Other DL (Bytes)', 'Other UL (Bytes)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(telecom_df[pca_columns])\n",
    "#Perform PCA\n",
    "pca = PCA()\n",
    "pca_data = pca.fit_transform(scaled_data)\n",
    "# Explained variance ratio\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "# Plot the explained variance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(explained_variance) + 1), explained_variance, marker='o')\n",
    "plt.title('Explained Variance by Principal Components')\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Variance Explained')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "# Optional but let Create a DataFrame for the PCA results\n",
    "pca_df = pd.DataFrame(data=pca_data, columns=[f'PC{i+1}' for i in range(len(pca_columns))])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
